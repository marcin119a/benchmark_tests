{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/marcin119a/PUMP2/main/long_dna.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8yPv3jtZ1vP",
        "outputId": "d203450c-de8b-47d9-af5a-ad78f877535a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-24 19:13:32--  https://raw.githubusercontent.com/marcin119a/PUMP2/main/long_dna.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 797472 (779K) [text/plain]\n",
            "Saving to: ‘long_dna.txt’\n",
            "\n",
            "long_dna.txt        100%[===================>] 778.78K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-24 19:13:32 (47.3 MB/s) - ‘long_dna.txt’ saved [797472/797472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_lines_in_file(file_name):\n",
        "    # Inicjalizacja licznika linii\n",
        "    line_count = 0\n",
        "\n",
        "    # Otwarcie pliku w trybie do odczytu\n",
        "    with open(file_name, 'r') as file:\n",
        "        for line in file:\n",
        "            line_count += 1\n",
        "\n",
        "    return line_count\n",
        "\n",
        "file_name = 'long_dna.txt'\n",
        "lines_count = count_lines_in_file(file_name)\n",
        "print(f\"Liczba linii w pliku '{file_name}': {lines_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUyjbV9QeQuD",
        "outputId": "3dc22f77-4929-4838-8837-793666190137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba linii w pliku 'long_dna.txt': 29536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data_file(data_path, num_samples):\n",
        "    # Inicjalizacja list dla danych wejściowych i wyjściowych oraz zbiorów znaków\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "\n",
        "    # Wczytanie danych z pliku txt\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().split('\\n')\n",
        "\n",
        "    # Przetwarzanie danych i zbiorów znaków\n",
        "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "        input_text, target_text = line.split(' ')\n",
        "        # Dodanie znaków startu i końca dla target_text\n",
        "        target_text = '\\t' + target_text + '\\n'\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "        # Aktualizacja zbiorów znaków\n",
        "        for char in input_text:\n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "        for char in target_text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "\n",
        "    return input_texts, target_texts, input_characters, target_characters\n",
        "\n",
        "num_samples = 20000\n",
        "data_path = 'long_dna.txt'\n",
        "input_texts, target_texts, input_characters, target_characters = parse_data_file(data_path, num_samples)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Liczba danych wejściowych:\", len(input_texts))\n",
        "print(\"Liczba danych wyjściowych:\", len(target_texts))\n",
        "print(\"Zbiór znaków wejściowych:\", input_characters)\n",
        "print(\"Zbiór znaków wyjściowych:\", target_characters)\n"
      ],
      "metadata": {
        "id": "PA3T8Y6wcO87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833241f9-2083-4127-f05d-f4b00181fe08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba danych wejściowych: 20000\n",
            "Liczba danych wyjściowych: 20000\n",
            "Zbiór znaków wejściowych: {'N', 'T', 'A', 'G', 'C'}\n",
            "Zbiór znaków wyjściowych: {'\\t', 'N', 'T', '\\n', 'A', 'G', 'C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85FcwVM_g1pQ",
        "outputId": "15b12249-adb5-402e-e916-09e8b687fbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A', 'C', 'G', 'N', 'T'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w37XfryGgyvJ",
        "outputId": "010b2e48-b89e-4c04-ffde-16cddfd1521f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t', '\\n', 'A', 'C', 'G', 'N', 'T'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "import numpy as np\n",
        "\n",
        "def create_token_index(tokens):\n",
        "    token_index = dict([(char, i) for i, char in enumerate(tokens)])\n",
        "    return token_index\n",
        "\n",
        "def transform_data(input_texts, target_texts, input_token_index, target_token_index, max_encoder_seq_length, max_decoder_seq_length):\n",
        "    num_samples = len(input_texts)\n",
        "    num_encoder_tokens = len(input_token_index)\n",
        "    num_decoder_tokens = len(target_token_index)\n",
        "\n",
        "    encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    decoder_input_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "        for t, char in enumerate(target_text):\n",
        "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "            if t > 0:\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "# Przykład użycia funkcji\n",
        "input_token_index = create_token_index(input_characters)\n",
        "target_token_index = create_token_index(target_characters)\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = transform_data(input_texts, target_texts, input_token_index, target_token_index, max_encoder_seq_length, max_decoder_seq_length)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Number of unique input tokens:\", len(input_token_index))\n",
        "print(\"Number of unique output tokens:\", len(target_token_index))\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg58ouHXZxPD",
        "outputId": "4e5ab8a3-3eae-4329-c5ef-21a73f008fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20000\n",
            "Number of unique input tokens: 5\n",
            "Number of unique output tokens: 7\n",
            "Max sequence length for inputs: 12\n",
            "Max sequence length for outputs: 14\n",
            "Number of unique input tokens: 5\n",
            "Number of unique output tokens: 7\n",
            "Max sequence length for inputs: 12\n",
            "Max sequence length for outputs: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('decoder_target_data.npz', decoder_target_data=decoder_target_data)"
      ],
      "metadata": {
        "id": "-7sstKmgiyyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('decoder_input_data.npz', decoder_input_data=decoder_input_data)"
      ],
      "metadata": {
        "id": "dItffeTGjjNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('encoder_input_data.npz', encoder_input_data=encoder_input_data)"
      ],
      "metadata": {
        "id": "awiuuSZoqPJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s.h5')\n"
      ],
      "metadata": {
        "id": "pjgCvauViv1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e036ea-e349-4e57-8c81-5f9208f1243e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 13s 14ms/step - loss: 1.1962 - accuracy: 0.3943 - val_loss: 0.9889 - val_accuracy: 0.4925\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.7753 - accuracy: 0.6102 - val_loss: 0.4895 - val_accuracy: 0.7461\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3911 - accuracy: 0.7909 - val_loss: 0.2704 - val_accuracy: 0.8391\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2199 - accuracy: 0.8586 - val_loss: 0.1719 - val_accuracy: 0.8727\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1443 - accuracy: 0.8778 - val_loss: 0.1291 - val_accuracy: 0.8798\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1408 - accuracy: 0.8751 - val_loss: 0.1308 - val_accuracy: 0.8778\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1200 - accuracy: 0.8798 - val_loss: 0.1165 - val_accuracy: 0.8800\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2507 - accuracy: 0.8308 - val_loss: 0.2328 - val_accuracy: 0.8577\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1569 - accuracy: 0.8773 - val_loss: 0.1392 - val_accuracy: 0.8807\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1314 - accuracy: 0.8800 - val_loss: 0.1179 - val_accuracy: 0.8808\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.8805 - val_loss: 0.1088 - val_accuracy: 0.8802\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1060 - accuracy: 0.8813 - val_loss: 0.1048 - val_accuracy: 0.8800\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1040 - accuracy: 0.8814 - val_loss: 0.1031 - val_accuracy: 0.8805\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1033 - accuracy: 0.8815 - val_loss: 0.1042 - val_accuracy: 0.8803\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.8814 - val_loss: 0.1029 - val_accuracy: 0.8798\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.8816 - val_loss: 0.1030 - val_accuracy: 0.8800\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3624 - accuracy: 0.8310 - val_loss: 1.9580 - val_accuracy: 0.2910\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1.0804 - accuracy: 0.4563 - val_loss: 0.8249 - val_accuracy: 0.5811\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.7062 - accuracy: 0.6378 - val_loss: 0.6157 - val_accuracy: 0.6820\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.5124 - accuracy: 0.7478 - val_loss: 0.4274 - val_accuracy: 0.8056\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3684 - accuracy: 0.8260 - val_loss: 0.3274 - val_accuracy: 0.8402\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2938 - accuracy: 0.8582 - val_loss: 0.2716 - val_accuracy: 0.8600\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2509 - accuracy: 0.8702 - val_loss: 0.2386 - val_accuracy: 0.8708\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2236 - accuracy: 0.8757 - val_loss: 0.2149 - val_accuracy: 0.8759\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2060 - accuracy: 0.8773 - val_loss: 0.2060 - val_accuracy: 0.8773\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1972 - accuracy: 0.8779 - val_loss: 0.1939 - val_accuracy: 0.8775\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1884 - accuracy: 0.8781 - val_loss: 0.1853 - val_accuracy: 0.8776\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1823 - accuracy: 0.8783 - val_loss: 0.1824 - val_accuracy: 0.8776\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1770 - accuracy: 0.8785 - val_loss: 0.1755 - val_accuracy: 0.8787\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1728 - accuracy: 0.8794 - val_loss: 0.1721 - val_accuracy: 0.8788\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1692 - accuracy: 0.8797 - val_loss: 0.1704 - val_accuracy: 0.8789\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1659 - accuracy: 0.8802 - val_loss: 0.1674 - val_accuracy: 0.8804\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1636 - accuracy: 0.8800 - val_loss: 0.1663 - val_accuracy: 0.8791\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1620 - accuracy: 0.8799 - val_loss: 0.1634 - val_accuracy: 0.8798\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.8803 - val_loss: 0.1596 - val_accuracy: 0.8782\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.8808 - val_loss: 0.1564 - val_accuracy: 0.8792\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1542 - accuracy: 0.8809 - val_loss: 0.1536 - val_accuracy: 0.8792\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1523 - accuracy: 0.8805 - val_loss: 0.1509 - val_accuracy: 0.8804\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7791 - val_loss: 0.2614 - val_accuracy: 0.8580\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2056 - accuracy: 0.8750 - val_loss: 0.1755 - val_accuracy: 0.8798\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1667 - accuracy: 0.8800 - val_loss: 0.1570 - val_accuracy: 0.8807\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1528 - accuracy: 0.8806 - val_loss: 0.1493 - val_accuracy: 0.8807\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.8807 - val_loss: 0.1440 - val_accuracy: 0.8800\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1389 - accuracy: 0.8812 - val_loss: 0.1362 - val_accuracy: 0.8804\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1330 - accuracy: 0.8815 - val_loss: 0.1336 - val_accuracy: 0.8804\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1268 - accuracy: 0.8815 - val_loss: 0.1245 - val_accuracy: 0.8813\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1238 - accuracy: 0.8816 - val_loss: 0.1229 - val_accuracy: 0.8801\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1218 - accuracy: 0.8816 - val_loss: 0.1224 - val_accuracy: 0.8803\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1198 - accuracy: 0.8815 - val_loss: 0.1194 - val_accuracy: 0.8798\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.8813 - val_loss: 0.1191 - val_accuracy: 0.8805\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.8818 - val_loss: 0.1181 - val_accuracy: 0.8806\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1163 - accuracy: 0.8815 - val_loss: 0.1167 - val_accuracy: 0.8806\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1152 - accuracy: 0.8818 - val_loss: 0.1158 - val_accuracy: 0.8811\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1143 - accuracy: 0.8820 - val_loss: 0.1153 - val_accuracy: 0.8799\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.8816 - val_loss: 0.1135 - val_accuracy: 0.8813\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1134 - accuracy: 0.8824 - val_loss: 0.1148 - val_accuracy: 0.8808\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1137 - accuracy: 0.8816 - val_loss: 0.1155 - val_accuracy: 0.8804\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1132 - accuracy: 0.8815 - val_loss: 0.1142 - val_accuracy: 0.8801\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1119 - accuracy: 0.8821 - val_loss: 0.1121 - val_accuracy: 0.8811\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1110 - accuracy: 0.8826 - val_loss: 0.1120 - val_accuracy: 0.8805\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1103 - accuracy: 0.8821 - val_loss: 0.1156 - val_accuracy: 0.8788\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1091 - accuracy: 0.8825 - val_loss: 0.1113 - val_accuracy: 0.8797\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1088 - accuracy: 0.8827 - val_loss: 0.1098 - val_accuracy: 0.8811\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1076 - accuracy: 0.8830 - val_loss: 0.1094 - val_accuracy: 0.8816\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1070 - accuracy: 0.8834 - val_loss: 0.1130 - val_accuracy: 0.8801\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1069 - accuracy: 0.8827 - val_loss: 0.1119 - val_accuracy: 0.8803\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1075 - accuracy: 0.8828 - val_loss: 0.1086 - val_accuracy: 0.8810\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1046 - accuracy: 0.8844 - val_loss: 0.1089 - val_accuracy: 0.8808\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1037 - accuracy: 0.8849 - val_loss: 0.1100 - val_accuracy: 0.8811\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.8851 - val_loss: 0.1094 - val_accuracy: 0.8811\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.8856 - val_loss: 0.1113 - val_accuracy: 0.8800\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1019 - accuracy: 0.8858 - val_loss: 0.1093 - val_accuracy: 0.8805\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1002 - accuracy: 0.8869 - val_loss: 0.1124 - val_accuracy: 0.8793\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0996 - accuracy: 0.8875 - val_loss: 0.1102 - val_accuracy: 0.8796\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.8884 - val_loss: 0.1122 - val_accuracy: 0.8796\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0970 - accuracy: 0.8891 - val_loss: 0.1114 - val_accuracy: 0.8798\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0962 - accuracy: 0.8894 - val_loss: 0.1123 - val_accuracy: 0.8796\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0952 - accuracy: 0.8899 - val_loss: 0.1140 - val_accuracy: 0.8806\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.8916 - val_loss: 0.1142 - val_accuracy: 0.8794\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.8928 - val_loss: 0.1143 - val_accuracy: 0.8788\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.8937 - val_loss: 0.1208 - val_accuracy: 0.8791\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.8961 - val_loss: 0.1170 - val_accuracy: 0.8797\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.8973 - val_loss: 0.1190 - val_accuracy: 0.8795\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.8982 - val_loss: 0.1249 - val_accuracy: 0.8772\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0777 - accuracy: 0.8993 - val_loss: 0.1201 - val_accuracy: 0.8785\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9006 - val_loss: 0.1223 - val_accuracy: 0.8801\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9041 - val_loss: 0.1242 - val_accuracy: 0.8800\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9059 - val_loss: 0.1268 - val_accuracy: 0.8784\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0658 - accuracy: 0.9058 - val_loss: 0.1289 - val_accuracy: 0.8779\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0618 - accuracy: 0.9078 - val_loss: 0.1323 - val_accuracy: 0.8778\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0601 - accuracy: 0.9088 - val_loss: 0.1338 - val_accuracy: 0.8785\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9092 - val_loss: 0.1346 - val_accuracy: 0.8787\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0573 - accuracy: 0.9100 - val_loss: 0.1368 - val_accuracy: 0.8772\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0516 - accuracy: 0.9133 - val_loss: 0.1378 - val_accuracy: 0.8781\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0480 - accuracy: 0.9147 - val_loss: 0.1425 - val_accuracy: 0.8775\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9164 - val_loss: 0.1418 - val_accuracy: 0.8773\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0437 - accuracy: 0.9171 - val_loss: 0.1475 - val_accuracy: 0.8786\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9174 - val_loss: 0.1468 - val_accuracy: 0.8772\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9179 - val_loss: 0.1513 - val_accuracy: 0.8782\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0401 - accuracy: 0.9186 - val_loss: 0.1521 - val_accuracy: 0.8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def matching_position_k_mers(result1, result2, space = True):\n",
        "\n",
        "  # Initialise counter of compatible items\n",
        "  matching_positions = 0\n",
        "  if space == True:\n",
        "    result2 = ' ' + result2\n",
        "  # Compare the letters in each position\n",
        "  for i in range(len(result1)):\n",
        "      if result1[i] == result2[i]:\n",
        "          matching_positions += 1\n",
        "\n",
        "  return {matching_positions}\n",
        "\n",
        "matching_position_k_mers('GTTTTGCAGCCG', 'TTTTGCAGCCGA')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1sjILi0isqK",
        "outputId": "5770b949-4db4-4bef-f793-31bce979b1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    print('On how many positions they agree on', matching_position_k_mers(input_texts[seq_index], decoded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ugd7nYbLTQ",
        "outputId": "d553e6e7-4522-487e-adca-6d6dd4d1fc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 570ms/step\n",
            "-\n",
            "Input sentence: GTTTTGCAGCCG\n",
            "Decoded sentence: TTTTGCAGCCGA\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TTTTGCAGCCGA\n",
            "Decoded sentence: TTTGCAGCCGAC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TTTGCAGCCGAT\n",
            "Decoded sentence: TTGCAGCCGATC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TTGCAGCCGATC\n",
            "Decoded sentence: TGCAGCCGATCA\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TGCAGCCGATCA\n",
            "Decoded sentence: GCAGCCGATCAC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-\n",
            "Input sentence: GCAGCCGATCAT\n",
            "Decoded sentence: CAGCCGATCATC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: CAGCCGATCATC\n",
            "Decoded sentence: AGCCGATCATCA\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: AGCCGATCATCA\n",
            "Decoded sentence: GCCGATCATCAG\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: GCCGATCATCAG\n",
            "Decoded sentence: CCGATCATCAGC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: CCGATCATCAGC\n",
            "Decoded sentence: CGATCATCAGCA\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-\n",
            "Input sentence: CGATCATCAGCA\n",
            "Decoded sentence: GATCATCAGCAC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: GATCATCAGCAC\n",
            "Decoded sentence: ATCATCAGCACT\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: ATCATCAGCACA\n",
            "Decoded sentence: TCATCAGCACAC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "-\n",
            "Input sentence: TCATCAGCACAT\n",
            "Decoded sentence: CATCAGCACATC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "-\n",
            "Input sentence: CATCAGCACATC\n",
            "Decoded sentence: ATCAGCACATCT\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: ATCAGCACATCT\n",
            "Decoded sentence: TCAGCACATCTA\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TCAGCACATCTA\n",
            "Decoded sentence: CAGCACATCTAC\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: CAGCACATCTAG\n",
            "Decoded sentence: AGCACATCTAGG\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: AGCACATCTAGG\n",
            "Decoded sentence: GCACATCTAGGT\n",
            "\n",
            "On how many positions they agree on {11}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GCACATCTAGGT\n",
            "Decoded sentence: CACATCTAGGTT\n",
            "\n",
            "On how many positions they agree on {11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/marcin119a/PUMP2/main/long_dna_errors.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-iFJ9mlkLIv",
        "outputId": "f1f87862-f6a3-4d8a-b052-b8380a497dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-24 19:16:02--  https://raw.githubusercontent.com/marcin119a/PUMP2/main/long_dna_errors.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 766688 (749K) [text/plain]\n",
            "Saving to: ‘long_dna_errors.txt’\n",
            "\n",
            "long_dna_errors.txt 100%[===================>] 748.72K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-24 19:16:02 (43.7 MB/s) - ‘long_dna_errors.txt’ saved [766688/766688]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corrected ERRORS by trained encoder-decoder network"
      ],
      "metadata": {
        "id": "IfEb6r2Jx483"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'long_dna_errors.txt'\n",
        "lines_count = count_lines_in_file(file_name)\n",
        "print(f\"Liczba linii w pliku '{file_name}': {lines_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5JFDJanxr-v",
        "outputId": "6a34a286-e70e-48e2-9030-d1e262ee066f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba linii w pliku 'long_dna_errors.txt': 29488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 20000\n",
        "data_path = 'long_dna_errors.txt'\n",
        "input_texts, target_texts, input_characters, target_characters = parse_data_file(data_path, num_samples)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Liczba danych wejściowych:\", len(input_texts))\n",
        "print(\"Liczba danych wyjściowych:\", len(target_texts))\n",
        "print(\"Zbiór znaków wejściowych:\", input_characters)\n",
        "print(\"Zbiór znaków wyjściowych:\", target_characters)\n"
      ],
      "metadata": {
        "id": "kXlQ7afkyKet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80da0f5a-0c89-4a50-cacd-cfee5d23ca3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba danych wejściowych: 20000\n",
            "Liczba danych wyjściowych: 20000\n",
            "Zbiór znaków wejściowych: {'T', 'A', 'N', 'G', 'C'}\n",
            "Zbiór znaków wyjściowych: {'\\t', 'T', 'A', '\\n', 'N', 'G', 'C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "input_token_index = create_token_index(input_characters)\n",
        "target_token_index = create_token_index(target_characters)\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = transform_data(input_texts, target_texts, input_token_index, target_token_index, max_encoder_seq_length, max_decoder_seq_length)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Number of unique input tokens:\", len(input_token_index))\n",
        "print(\"Number of unique output tokens:\", len(target_token_index))\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo-1_3CzyCsi",
        "outputId": "64e2d45c-ee47-4103-af37-475f9fd5bd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique input tokens: 5\n",
            "Number of unique output tokens: 7\n",
            "Max sequence length for inputs: 12\n",
            "Max sequence length for outputs: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=300,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckl8-ZbcOOJo",
        "outputId": "22fc518e-b72a-44b4-bcd3-d3fdb7fde23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.6245 - accuracy: 0.4134 - val_loss: 0.9500 - val_accuracy: 0.5447\n",
            "Epoch 2/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8438 - accuracy: 0.5966 - val_loss: 0.7679 - val_accuracy: 0.6293\n",
            "Epoch 3/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6972 - accuracy: 0.6721 - val_loss: 0.6582 - val_accuracy: 0.6949\n",
            "Epoch 4/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6045 - accuracy: 0.7191 - val_loss: 0.5842 - val_accuracy: 0.7259\n",
            "Epoch 5/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.5396 - accuracy: 0.7487 - val_loss: 0.5222 - val_accuracy: 0.7615\n",
            "Epoch 6/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.4996 - accuracy: 0.7651 - val_loss: 0.4927 - val_accuracy: 0.7720\n",
            "Epoch 7/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4684 - accuracy: 0.7763 - val_loss: 0.4668 - val_accuracy: 0.7800\n",
            "Epoch 8/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.4432 - accuracy: 0.7849 - val_loss: 0.4524 - val_accuracy: 0.7781\n",
            "Epoch 9/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4278 - accuracy: 0.7906 - val_loss: 0.4478 - val_accuracy: 0.7811\n",
            "Epoch 10/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4106 - accuracy: 0.7958 - val_loss: 0.4357 - val_accuracy: 0.7807\n",
            "Epoch 11/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3982 - accuracy: 0.7995 - val_loss: 0.4072 - val_accuracy: 0.8027\n",
            "Epoch 12/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3871 - accuracy: 0.8032 - val_loss: 0.4073 - val_accuracy: 0.7952\n",
            "Epoch 13/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3778 - accuracy: 0.8065 - val_loss: 0.4076 - val_accuracy: 0.7929\n",
            "Epoch 14/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3699 - accuracy: 0.8092 - val_loss: 0.3924 - val_accuracy: 0.7990\n",
            "Epoch 15/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3610 - accuracy: 0.8128 - val_loss: 0.3887 - val_accuracy: 0.8042\n",
            "Epoch 16/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3543 - accuracy: 0.8152 - val_loss: 0.3831 - val_accuracy: 0.7965\n",
            "Epoch 17/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3480 - accuracy: 0.8174 - val_loss: 0.3827 - val_accuracy: 0.8025\n",
            "Epoch 18/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.3400 - accuracy: 0.8214 - val_loss: 0.3871 - val_accuracy: 0.8016\n",
            "Epoch 19/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3331 - accuracy: 0.8245 - val_loss: 0.3848 - val_accuracy: 0.8085\n",
            "Epoch 20/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.8275 - val_loss: 0.3728 - val_accuracy: 0.8162\n",
            "Epoch 21/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3219 - accuracy: 0.8304 - val_loss: 0.3588 - val_accuracy: 0.8162\n",
            "Epoch 22/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3142 - accuracy: 0.8335 - val_loss: 0.3620 - val_accuracy: 0.8201\n",
            "Epoch 23/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3080 - accuracy: 0.8366 - val_loss: 0.3575 - val_accuracy: 0.8179\n",
            "Epoch 24/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3015 - accuracy: 0.8393 - val_loss: 0.3704 - val_accuracy: 0.8124\n",
            "Epoch 25/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2946 - accuracy: 0.8426 - val_loss: 0.3576 - val_accuracy: 0.8192\n",
            "Epoch 26/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2900 - accuracy: 0.8451 - val_loss: 0.3528 - val_accuracy: 0.8211\n",
            "Epoch 27/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2837 - accuracy: 0.8475 - val_loss: 0.3528 - val_accuracy: 0.8247\n",
            "Epoch 28/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2780 - accuracy: 0.8501 - val_loss: 0.3492 - val_accuracy: 0.8268\n",
            "Epoch 29/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2722 - accuracy: 0.8525 - val_loss: 0.3614 - val_accuracy: 0.8251\n",
            "Epoch 30/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2673 - accuracy: 0.8548 - val_loss: 0.3510 - val_accuracy: 0.8220\n",
            "Epoch 31/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2626 - accuracy: 0.8563 - val_loss: 0.3655 - val_accuracy: 0.8172\n",
            "Epoch 32/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2598 - accuracy: 0.8574 - val_loss: 0.3545 - val_accuracy: 0.8291\n",
            "Epoch 33/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2532 - accuracy: 0.8602 - val_loss: 0.3526 - val_accuracy: 0.8278\n",
            "Epoch 34/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2491 - accuracy: 0.8619 - val_loss: 0.3563 - val_accuracy: 0.8272\n",
            "Epoch 35/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2443 - accuracy: 0.8643 - val_loss: 0.3653 - val_accuracy: 0.8245\n",
            "Epoch 36/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2398 - accuracy: 0.8661 - val_loss: 0.3587 - val_accuracy: 0.8271\n",
            "Epoch 37/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2385 - accuracy: 0.8659 - val_loss: 0.3626 - val_accuracy: 0.8274\n",
            "Epoch 38/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2334 - accuracy: 0.8688 - val_loss: 0.3553 - val_accuracy: 0.8281\n",
            "Epoch 39/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.8704 - val_loss: 0.3687 - val_accuracy: 0.8263\n",
            "Epoch 40/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2266 - accuracy: 0.8715 - val_loss: 0.3538 - val_accuracy: 0.8253\n",
            "Epoch 41/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2223 - accuracy: 0.8735 - val_loss: 0.3629 - val_accuracy: 0.8265\n",
            "Epoch 42/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2191 - accuracy: 0.8749 - val_loss: 0.3654 - val_accuracy: 0.8217\n",
            "Epoch 43/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2157 - accuracy: 0.8762 - val_loss: 0.3668 - val_accuracy: 0.8280\n",
            "Epoch 44/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2156 - accuracy: 0.8757 - val_loss: 0.3682 - val_accuracy: 0.8301\n",
            "Epoch 45/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2139 - accuracy: 0.8764 - val_loss: 0.3684 - val_accuracy: 0.8279\n",
            "Epoch 46/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2091 - accuracy: 0.8788 - val_loss: 0.3680 - val_accuracy: 0.8293\n",
            "Epoch 47/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2111 - accuracy: 0.8768 - val_loss: 0.3635 - val_accuracy: 0.8300\n",
            "Epoch 48/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2058 - accuracy: 0.8796 - val_loss: 0.3650 - val_accuracy: 0.8296\n",
            "Epoch 49/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2054 - accuracy: 0.8794 - val_loss: 0.3721 - val_accuracy: 0.8263\n",
            "Epoch 50/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2045 - accuracy: 0.8796 - val_loss: 0.3713 - val_accuracy: 0.8311\n",
            "Epoch 51/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2065 - accuracy: 0.8780 - val_loss: 0.3758 - val_accuracy: 0.8285\n",
            "Epoch 52/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2017 - accuracy: 0.8807 - val_loss: 0.3728 - val_accuracy: 0.8234\n",
            "Epoch 53/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1997 - accuracy: 0.8809 - val_loss: 0.3718 - val_accuracy: 0.8314\n",
            "Epoch 54/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1960 - accuracy: 0.8831 - val_loss: 0.3809 - val_accuracy: 0.8278\n",
            "Epoch 55/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1959 - accuracy: 0.8829 - val_loss: 0.3763 - val_accuracy: 0.8282\n",
            "Epoch 56/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1952 - accuracy: 0.8830 - val_loss: 0.3738 - val_accuracy: 0.8326\n",
            "Epoch 57/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1914 - accuracy: 0.8843 - val_loss: 0.3769 - val_accuracy: 0.8303\n",
            "Epoch 58/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.8851 - val_loss: 0.3863 - val_accuracy: 0.8298\n",
            "Epoch 59/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1892 - accuracy: 0.8850 - val_loss: 0.3854 - val_accuracy: 0.8308\n",
            "Epoch 60/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1906 - accuracy: 0.8847 - val_loss: 0.3883 - val_accuracy: 0.8296\n",
            "Epoch 61/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1911 - accuracy: 0.8848 - val_loss: 0.3784 - val_accuracy: 0.8340\n",
            "Epoch 62/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1903 - accuracy: 0.8848 - val_loss: 0.3797 - val_accuracy: 0.8330\n",
            "Epoch 63/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1862 - accuracy: 0.8872 - val_loss: 0.3808 - val_accuracy: 0.8355\n",
            "Epoch 64/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1837 - accuracy: 0.8875 - val_loss: 0.3796 - val_accuracy: 0.8331\n",
            "Epoch 65/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1810 - accuracy: 0.8890 - val_loss: 0.3794 - val_accuracy: 0.8308\n",
            "Epoch 66/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.8921 - val_loss: 0.3770 - val_accuracy: 0.8348\n",
            "Epoch 67/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1719 - accuracy: 0.8921 - val_loss: 0.3787 - val_accuracy: 0.8333\n",
            "Epoch 68/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1677 - accuracy: 0.8917 - val_loss: 0.3751 - val_accuracy: 0.8335\n",
            "Epoch 69/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1636 - accuracy: 0.8908 - val_loss: 0.3652 - val_accuracy: 0.8367\n",
            "Epoch 70/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1591 - accuracy: 0.8909 - val_loss: 0.3550 - val_accuracy: 0.8373\n",
            "Epoch 71/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1560 - accuracy: 0.8904 - val_loss: 0.3501 - val_accuracy: 0.8370\n",
            "Epoch 72/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1479 - accuracy: 0.8931 - val_loss: 0.3459 - val_accuracy: 0.8376\n",
            "Epoch 73/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.8947 - val_loss: 0.3637 - val_accuracy: 0.8342\n",
            "Epoch 74/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1377 - accuracy: 0.8953 - val_loss: 0.3448 - val_accuracy: 0.8369\n",
            "Epoch 75/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.8961 - val_loss: 0.3572 - val_accuracy: 0.8356\n",
            "Epoch 76/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1367 - accuracy: 0.8946 - val_loss: 0.3530 - val_accuracy: 0.8363\n",
            "Epoch 77/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1372 - accuracy: 0.8938 - val_loss: 0.3491 - val_accuracy: 0.8364\n",
            "Epoch 78/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.8967 - val_loss: 0.3486 - val_accuracy: 0.8398\n",
            "Epoch 79/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1254 - accuracy: 0.8991 - val_loss: 0.3555 - val_accuracy: 0.8359\n",
            "Epoch 80/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1221 - accuracy: 0.9003 - val_loss: 0.3490 - val_accuracy: 0.8378\n",
            "Epoch 81/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1203 - accuracy: 0.9007 - val_loss: 0.3555 - val_accuracy: 0.8380\n",
            "Epoch 82/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1202 - accuracy: 0.9007 - val_loss: 0.3525 - val_accuracy: 0.8381\n",
            "Epoch 83/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1244 - accuracy: 0.8980 - val_loss: 0.3607 - val_accuracy: 0.8366\n",
            "Epoch 84/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.8988 - val_loss: 0.3526 - val_accuracy: 0.8387\n",
            "Epoch 85/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1290 - accuracy: 0.8955 - val_loss: 0.3552 - val_accuracy: 0.8357\n",
            "Epoch 86/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1343 - accuracy: 0.8927 - val_loss: 0.3559 - val_accuracy: 0.8357\n",
            "Epoch 87/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1261 - accuracy: 0.8968 - val_loss: 0.3586 - val_accuracy: 0.8348\n",
            "Epoch 88/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1229 - accuracy: 0.8984 - val_loss: 0.3445 - val_accuracy: 0.8407\n",
            "Epoch 89/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.9010 - val_loss: 0.3469 - val_accuracy: 0.8385\n",
            "Epoch 90/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.9031 - val_loss: 0.3588 - val_accuracy: 0.8334\n",
            "Epoch 91/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9038 - val_loss: 0.3569 - val_accuracy: 0.8361\n",
            "Epoch 92/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1094 - accuracy: 0.9040 - val_loss: 0.3555 - val_accuracy: 0.8379\n",
            "Epoch 93/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1085 - accuracy: 0.9041 - val_loss: 0.3518 - val_accuracy: 0.8375\n",
            "Epoch 94/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1145 - accuracy: 0.9013 - val_loss: 0.3523 - val_accuracy: 0.8387\n",
            "Epoch 95/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1207 - accuracy: 0.8983 - val_loss: 0.3603 - val_accuracy: 0.8353\n",
            "Epoch 96/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1276 - accuracy: 0.8953 - val_loss: 0.3557 - val_accuracy: 0.8359\n",
            "Epoch 97/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1261 - accuracy: 0.8951 - val_loss: 0.3517 - val_accuracy: 0.8386\n",
            "Epoch 98/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1163 - accuracy: 0.9001 - val_loss: 0.3439 - val_accuracy: 0.8407\n",
            "Epoch 99/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1078 - accuracy: 0.9042 - val_loss: 0.3510 - val_accuracy: 0.8389\n",
            "Epoch 100/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1082 - accuracy: 0.9038 - val_loss: 0.3555 - val_accuracy: 0.8375\n",
            "Epoch 101/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1055 - accuracy: 0.9046 - val_loss: 0.3599 - val_accuracy: 0.8372\n",
            "Epoch 102/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1028 - accuracy: 0.9061 - val_loss: 0.3507 - val_accuracy: 0.8413\n",
            "Epoch 103/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1065 - accuracy: 0.9046 - val_loss: 0.3516 - val_accuracy: 0.8408\n",
            "Epoch 104/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1034 - accuracy: 0.9058 - val_loss: 0.3675 - val_accuracy: 0.8347\n",
            "Epoch 105/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1034 - accuracy: 0.9054 - val_loss: 0.3487 - val_accuracy: 0.8406\n",
            "Epoch 106/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1128 - accuracy: 0.9004 - val_loss: 0.3602 - val_accuracy: 0.8379\n",
            "Epoch 107/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1101 - accuracy: 0.9021 - val_loss: 0.3587 - val_accuracy: 0.8371\n",
            "Epoch 108/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1103 - accuracy: 0.9021 - val_loss: 0.3571 - val_accuracy: 0.8395\n",
            "Epoch 109/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9013 - val_loss: 0.3760 - val_accuracy: 0.8333\n",
            "Epoch 110/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9012 - val_loss: 0.3605 - val_accuracy: 0.8380\n",
            "Epoch 111/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9040 - val_loss: 0.3545 - val_accuracy: 0.8397\n",
            "Epoch 112/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1012 - accuracy: 0.9061 - val_loss: 0.3558 - val_accuracy: 0.8401\n",
            "Epoch 113/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9077 - val_loss: 0.3513 - val_accuracy: 0.8422\n",
            "Epoch 114/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9088 - val_loss: 0.3512 - val_accuracy: 0.8404\n",
            "Epoch 115/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0949 - accuracy: 0.9086 - val_loss: 0.3541 - val_accuracy: 0.8403\n",
            "Epoch 116/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0956 - accuracy: 0.9081 - val_loss: 0.3533 - val_accuracy: 0.8422\n",
            "Epoch 117/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0980 - accuracy: 0.9069 - val_loss: 0.3603 - val_accuracy: 0.8396\n",
            "Epoch 118/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1000 - accuracy: 0.9060 - val_loss: 0.3575 - val_accuracy: 0.8415\n",
            "Epoch 119/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1049 - accuracy: 0.9038 - val_loss: 0.3656 - val_accuracy: 0.8379\n",
            "Epoch 120/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.8957 - val_loss: 0.3628 - val_accuracy: 0.8369\n",
            "Epoch 121/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1187 - accuracy: 0.8971 - val_loss: 0.3771 - val_accuracy: 0.8309\n",
            "Epoch 122/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1082 - accuracy: 0.9019 - val_loss: 0.3609 - val_accuracy: 0.8385\n",
            "Epoch 123/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0995 - accuracy: 0.9060 - val_loss: 0.3555 - val_accuracy: 0.8426\n",
            "Epoch 124/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0939 - accuracy: 0.9085 - val_loss: 0.3525 - val_accuracy: 0.8412\n",
            "Epoch 125/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0913 - accuracy: 0.9093 - val_loss: 0.3571 - val_accuracy: 0.8413\n",
            "Epoch 126/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9096 - val_loss: 0.3622 - val_accuracy: 0.8397\n",
            "Epoch 127/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0900 - accuracy: 0.9098 - val_loss: 0.3573 - val_accuracy: 0.8425\n",
            "Epoch 128/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0907 - accuracy: 0.9093 - val_loss: 0.3791 - val_accuracy: 0.8370\n",
            "Epoch 129/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1006 - accuracy: 0.9050 - val_loss: 0.3724 - val_accuracy: 0.8376\n",
            "Epoch 130/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1045 - accuracy: 0.9028 - val_loss: 0.3679 - val_accuracy: 0.8362\n",
            "Epoch 131/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.8999 - val_loss: 0.3656 - val_accuracy: 0.8384\n",
            "Epoch 132/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1070 - accuracy: 0.9022 - val_loss: 0.3634 - val_accuracy: 0.8388\n",
            "Epoch 133/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1039 - accuracy: 0.9034 - val_loss: 0.3578 - val_accuracy: 0.8406\n",
            "Epoch 134/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0987 - accuracy: 0.9057 - val_loss: 0.3555 - val_accuracy: 0.8427\n",
            "Epoch 135/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0927 - accuracy: 0.9084 - val_loss: 0.3675 - val_accuracy: 0.8383\n",
            "Epoch 136/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9092 - val_loss: 0.3646 - val_accuracy: 0.8401\n",
            "Epoch 137/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9100 - val_loss: 0.3644 - val_accuracy: 0.8405\n",
            "Epoch 138/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0878 - accuracy: 0.9103 - val_loss: 0.3610 - val_accuracy: 0.8413\n",
            "Epoch 139/300\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.0894 - accuracy: 0.9094 - val_loss: 0.3817 - val_accuracy: 0.8346\n",
            "Epoch 140/300\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0911 - accuracy: 0.9086 - val_loss: 0.3597 - val_accuracy: 0.8410\n",
            "Epoch 141/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0955 - accuracy: 0.9069 - val_loss: 0.4081 - val_accuracy: 0.8275\n",
            "Epoch 142/300\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.1156 - accuracy: 0.8974 - val_loss: 0.3662 - val_accuracy: 0.8374\n",
            "Epoch 143/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1212 - accuracy: 0.8955 - val_loss: 0.3659 - val_accuracy: 0.8379\n",
            "Epoch 144/300\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.1108 - accuracy: 0.8994 - val_loss: 0.3734 - val_accuracy: 0.8389\n",
            "Epoch 145/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0962 - accuracy: 0.9066 - val_loss: 0.3719 - val_accuracy: 0.8387\n",
            "Epoch 146/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0897 - accuracy: 0.9092 - val_loss: 0.3669 - val_accuracy: 0.8402\n",
            "Epoch 147/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0879 - accuracy: 0.9098 - val_loss: 0.3703 - val_accuracy: 0.8405\n",
            "Epoch 148/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0862 - accuracy: 0.9107 - val_loss: 0.3878 - val_accuracy: 0.8363\n",
            "Epoch 149/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9094 - val_loss: 0.3708 - val_accuracy: 0.8389\n",
            "Epoch 150/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0883 - accuracy: 0.9096 - val_loss: 0.3663 - val_accuracy: 0.8423\n",
            "Epoch 151/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0850 - accuracy: 0.9110 - val_loss: 0.3643 - val_accuracy: 0.8411\n",
            "Epoch 152/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0870 - accuracy: 0.9098 - val_loss: 0.3661 - val_accuracy: 0.8408\n",
            "Epoch 153/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0854 - accuracy: 0.9105 - val_loss: 0.3674 - val_accuracy: 0.8409\n",
            "Epoch 154/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0920 - accuracy: 0.9077 - val_loss: 0.3778 - val_accuracy: 0.8378\n",
            "Epoch 155/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1106 - accuracy: 0.8994 - val_loss: 0.3774 - val_accuracy: 0.8368\n",
            "Epoch 156/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1081 - accuracy: 0.9008 - val_loss: 0.3621 - val_accuracy: 0.8409\n",
            "Epoch 157/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.9050 - val_loss: 0.3699 - val_accuracy: 0.8391\n",
            "Epoch 158/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0907 - accuracy: 0.9082 - val_loss: 0.3629 - val_accuracy: 0.8430\n",
            "Epoch 159/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0894 - accuracy: 0.9084 - val_loss: 0.3746 - val_accuracy: 0.8399\n",
            "Epoch 160/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0878 - accuracy: 0.9093 - val_loss: 0.3698 - val_accuracy: 0.8390\n",
            "Epoch 161/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0887 - accuracy: 0.9087 - val_loss: 0.3694 - val_accuracy: 0.8412\n",
            "Epoch 162/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9089 - val_loss: 0.3691 - val_accuracy: 0.8420\n",
            "Epoch 163/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0890 - accuracy: 0.9084 - val_loss: 0.3711 - val_accuracy: 0.8392\n",
            "Epoch 164/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9078 - val_loss: 0.3771 - val_accuracy: 0.8402\n",
            "Epoch 165/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0909 - accuracy: 0.9071 - val_loss: 0.3674 - val_accuracy: 0.8401\n",
            "Epoch 166/300\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.0921 - accuracy: 0.9052 - val_loss: 0.3723 - val_accuracy: 0.8396\n",
            "Epoch 167/300\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0883 - accuracy: 0.9060 - val_loss: 0.3701 - val_accuracy: 0.8399\n",
            "Epoch 168/300\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.0872 - accuracy: 0.9068 - val_loss: 0.3725 - val_accuracy: 0.8412\n",
            "Epoch 169/300\n",
            "125/125 [==============================] - 2s 19ms/step - loss: 0.0854 - accuracy: 0.9072 - val_loss: 0.3718 - val_accuracy: 0.8408\n",
            "Epoch 170/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0810 - accuracy: 0.9092 - val_loss: 0.3664 - val_accuracy: 0.8417\n",
            "Epoch 171/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9096 - val_loss: 0.3725 - val_accuracy: 0.8411\n",
            "Epoch 172/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9092 - val_loss: 0.3636 - val_accuracy: 0.8436\n",
            "Epoch 173/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0776 - accuracy: 0.9101 - val_loss: 0.3720 - val_accuracy: 0.8420\n",
            "Epoch 174/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9087 - val_loss: 0.3741 - val_accuracy: 0.8419\n",
            "Epoch 175/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9073 - val_loss: 0.3753 - val_accuracy: 0.8409\n",
            "Epoch 176/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0879 - accuracy: 0.9053 - val_loss: 0.3787 - val_accuracy: 0.8403\n",
            "Epoch 177/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0869 - accuracy: 0.9059 - val_loss: 0.3763 - val_accuracy: 0.8395\n",
            "Epoch 178/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0824 - accuracy: 0.9079 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 179/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9095 - val_loss: 0.3787 - val_accuracy: 0.8409\n",
            "Epoch 180/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0765 - accuracy: 0.9102 - val_loss: 0.3701 - val_accuracy: 0.8428\n",
            "Epoch 181/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0735 - accuracy: 0.9114 - val_loss: 0.3724 - val_accuracy: 0.8422\n",
            "Epoch 182/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0703 - accuracy: 0.9131 - val_loss: 0.3785 - val_accuracy: 0.8422\n",
            "Epoch 183/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0696 - accuracy: 0.9132 - val_loss: 0.3750 - val_accuracy: 0.8441\n",
            "Epoch 184/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0684 - accuracy: 0.9137 - val_loss: 0.3784 - val_accuracy: 0.8444\n",
            "Epoch 185/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9100 - val_loss: 0.3726 - val_accuracy: 0.8428\n",
            "Epoch 186/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0826 - accuracy: 0.9074 - val_loss: 0.3829 - val_accuracy: 0.8411\n",
            "Epoch 187/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0923 - accuracy: 0.9032 - val_loss: 0.3870 - val_accuracy: 0.8338\n",
            "Epoch 188/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0914 - accuracy: 0.9030 - val_loss: 0.3815 - val_accuracy: 0.8399\n",
            "Epoch 189/300\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0802 - accuracy: 0.9084 - val_loss: 0.3744 - val_accuracy: 0.8429\n",
            "Epoch 190/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9113 - val_loss: 0.3719 - val_accuracy: 0.8429\n",
            "Epoch 191/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0691 - accuracy: 0.9132 - val_loss: 0.3741 - val_accuracy: 0.8439\n",
            "Epoch 192/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9126 - val_loss: 0.3735 - val_accuracy: 0.8440\n",
            "Epoch 193/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0701 - accuracy: 0.9127 - val_loss: 0.3747 - val_accuracy: 0.8439\n",
            "Epoch 194/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0661 - accuracy: 0.9143 - val_loss: 0.3714 - val_accuracy: 0.8444\n",
            "Epoch 195/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0695 - accuracy: 0.9126 - val_loss: 0.3831 - val_accuracy: 0.8414\n",
            "Epoch 196/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0690 - accuracy: 0.9130 - val_loss: 0.3869 - val_accuracy: 0.8417\n",
            "Epoch 197/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0703 - accuracy: 0.9121 - val_loss: 0.3853 - val_accuracy: 0.8435\n",
            "Epoch 198/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9117 - val_loss: 0.3763 - val_accuracy: 0.8434\n",
            "Epoch 199/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0728 - accuracy: 0.9112 - val_loss: 0.3833 - val_accuracy: 0.8407\n",
            "Epoch 200/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0745 - accuracy: 0.9106 - val_loss: 0.3829 - val_accuracy: 0.8439\n",
            "Epoch 201/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0716 - accuracy: 0.9116 - val_loss: 0.3808 - val_accuracy: 0.8433\n",
            "Epoch 202/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0823 - accuracy: 0.9063 - val_loss: 0.3830 - val_accuracy: 0.8418\n",
            "Epoch 203/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0812 - accuracy: 0.9072 - val_loss: 0.3918 - val_accuracy: 0.8390\n",
            "Epoch 204/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0811 - accuracy: 0.9071 - val_loss: 0.3786 - val_accuracy: 0.8408\n",
            "Epoch 205/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0743 - accuracy: 0.9104 - val_loss: 0.3758 - val_accuracy: 0.8457\n",
            "Epoch 206/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0706 - accuracy: 0.9119 - val_loss: 0.3943 - val_accuracy: 0.8401\n",
            "Epoch 207/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9131 - val_loss: 0.3849 - val_accuracy: 0.8418\n",
            "Epoch 208/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0675 - accuracy: 0.9132 - val_loss: 0.3832 - val_accuracy: 0.8424\n",
            "Epoch 209/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9143 - val_loss: 0.3758 - val_accuracy: 0.8455\n",
            "Epoch 210/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0635 - accuracy: 0.9150 - val_loss: 0.3984 - val_accuracy: 0.8406\n",
            "Epoch 211/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0624 - accuracy: 0.9153 - val_loss: 0.3767 - val_accuracy: 0.8454\n",
            "Epoch 212/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0617 - accuracy: 0.9156 - val_loss: 0.4125 - val_accuracy: 0.8369\n",
            "Epoch 213/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0663 - accuracy: 0.9134 - val_loss: 0.3916 - val_accuracy: 0.8416\n",
            "Epoch 214/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0749 - accuracy: 0.9096 - val_loss: 0.4060 - val_accuracy: 0.8378\n",
            "Epoch 215/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9038 - val_loss: 0.3886 - val_accuracy: 0.8426\n",
            "Epoch 216/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0958 - accuracy: 0.9009 - val_loss: 0.3920 - val_accuracy: 0.8384\n",
            "Epoch 217/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0871 - accuracy: 0.9046 - val_loss: 0.3767 - val_accuracy: 0.8442\n",
            "Epoch 218/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0751 - accuracy: 0.9097 - val_loss: 0.3775 - val_accuracy: 0.8441\n",
            "Epoch 219/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0700 - accuracy: 0.9120 - val_loss: 0.3810 - val_accuracy: 0.8441\n",
            "Epoch 220/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0665 - accuracy: 0.9135 - val_loss: 0.3734 - val_accuracy: 0.8466\n",
            "Epoch 221/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0618 - accuracy: 0.9154 - val_loss: 0.3683 - val_accuracy: 0.8473\n",
            "Epoch 222/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0614 - accuracy: 0.9157 - val_loss: 0.3908 - val_accuracy: 0.8431\n",
            "Epoch 223/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0597 - accuracy: 0.9162 - val_loss: 0.3797 - val_accuracy: 0.8443\n",
            "Epoch 224/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0586 - accuracy: 0.9168 - val_loss: 0.3852 - val_accuracy: 0.8446\n",
            "Epoch 225/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0581 - accuracy: 0.9171 - val_loss: 0.3809 - val_accuracy: 0.8456\n",
            "Epoch 226/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0604 - accuracy: 0.9158 - val_loss: 0.3779 - val_accuracy: 0.8472\n",
            "Epoch 227/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0630 - accuracy: 0.9147 - val_loss: 0.3805 - val_accuracy: 0.8468\n",
            "Epoch 228/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0630 - accuracy: 0.9149 - val_loss: 0.3880 - val_accuracy: 0.8445\n",
            "Epoch 229/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0720 - accuracy: 0.9106 - val_loss: 0.3982 - val_accuracy: 0.8365\n",
            "Epoch 230/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1066 - accuracy: 0.8958 - val_loss: 0.3933 - val_accuracy: 0.8411\n",
            "Epoch 231/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0880 - accuracy: 0.9039 - val_loss: 0.3754 - val_accuracy: 0.8454\n",
            "Epoch 232/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0739 - accuracy: 0.9103 - val_loss: 0.3836 - val_accuracy: 0.8431\n",
            "Epoch 233/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9135 - val_loss: 0.3747 - val_accuracy: 0.8460\n",
            "Epoch 234/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0619 - accuracy: 0.9152 - val_loss: 0.3906 - val_accuracy: 0.8446\n",
            "Epoch 235/300\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9117 - val_loss: 0.3929 - val_accuracy: 0.8430\n",
            "Epoch 236/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9149 - val_loss: 0.3811 - val_accuracy: 0.8470\n",
            "Epoch 237/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0610 - accuracy: 0.9155 - val_loss: 0.3780 - val_accuracy: 0.8472\n",
            "Epoch 238/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9126 - val_loss: 0.3785 - val_accuracy: 0.8469\n",
            "Epoch 239/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0632 - accuracy: 0.9141 - val_loss: 0.3806 - val_accuracy: 0.8461\n",
            "Epoch 240/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9106 - val_loss: 0.3855 - val_accuracy: 0.8429\n",
            "Epoch 241/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9094 - val_loss: 0.3789 - val_accuracy: 0.8455\n",
            "Epoch 242/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9121 - val_loss: 0.3831 - val_accuracy: 0.8460\n",
            "Epoch 243/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0635 - accuracy: 0.9143 - val_loss: 0.3810 - val_accuracy: 0.8465\n",
            "Epoch 244/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0612 - accuracy: 0.9154 - val_loss: 0.3841 - val_accuracy: 0.8455\n",
            "Epoch 245/300\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.0615 - accuracy: 0.9151 - val_loss: 0.3845 - val_accuracy: 0.8456\n",
            "Epoch 246/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0603 - accuracy: 0.9157 - val_loss: 0.3863 - val_accuracy: 0.8461\n",
            "Epoch 247/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9132 - val_loss: 0.3897 - val_accuracy: 0.8456\n",
            "Epoch 248/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0720 - accuracy: 0.9100 - val_loss: 0.4042 - val_accuracy: 0.8428\n",
            "Epoch 249/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9101 - val_loss: 0.3800 - val_accuracy: 0.8475\n",
            "Epoch 250/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0677 - accuracy: 0.9124 - val_loss: 0.3996 - val_accuracy: 0.8431\n",
            "Epoch 251/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0682 - accuracy: 0.9118 - val_loss: 0.3860 - val_accuracy: 0.8442\n",
            "Epoch 252/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0621 - accuracy: 0.9149 - val_loss: 0.3772 - val_accuracy: 0.8471\n",
            "Epoch 253/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0584 - accuracy: 0.9166 - val_loss: 0.3912 - val_accuracy: 0.8446\n",
            "Epoch 254/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9161 - val_loss: 0.3799 - val_accuracy: 0.8475\n",
            "Epoch 255/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9162 - val_loss: 0.3786 - val_accuracy: 0.8483\n",
            "Epoch 256/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0593 - accuracy: 0.9158 - val_loss: 0.3862 - val_accuracy: 0.8481\n",
            "Epoch 257/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0575 - accuracy: 0.9166 - val_loss: 0.3845 - val_accuracy: 0.8463\n",
            "Epoch 258/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2901 - accuracy: 0.8638 - val_loss: 0.9700 - val_accuracy: 0.6985\n",
            "Epoch 259/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5187 - accuracy: 0.7681 - val_loss: 0.4902 - val_accuracy: 0.7667\n",
            "Epoch 260/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3127 - accuracy: 0.8205 - val_loss: 0.4388 - val_accuracy: 0.8044\n",
            "Epoch 261/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2378 - accuracy: 0.8480 - val_loss: 0.4212 - val_accuracy: 0.8113\n",
            "Epoch 262/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2045 - accuracy: 0.8609 - val_loss: 0.4134 - val_accuracy: 0.8150\n",
            "Epoch 263/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1810 - accuracy: 0.8705 - val_loss: 0.4035 - val_accuracy: 0.8243\n",
            "Epoch 264/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1670 - accuracy: 0.8771 - val_loss: 0.4131 - val_accuracy: 0.8247\n",
            "Epoch 265/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1576 - accuracy: 0.8809 - val_loss: 0.4073 - val_accuracy: 0.8288\n",
            "Epoch 266/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1508 - accuracy: 0.8836 - val_loss: 0.4081 - val_accuracy: 0.8284\n",
            "Epoch 267/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1455 - accuracy: 0.8862 - val_loss: 0.4081 - val_accuracy: 0.8299\n",
            "Epoch 268/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1395 - accuracy: 0.8880 - val_loss: 0.4056 - val_accuracy: 0.8328\n",
            "Epoch 269/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1343 - accuracy: 0.8904 - val_loss: 0.4037 - val_accuracy: 0.8335\n",
            "Epoch 270/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1290 - accuracy: 0.8927 - val_loss: 0.4029 - val_accuracy: 0.8358\n",
            "Epoch 271/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1274 - accuracy: 0.8936 - val_loss: 0.4088 - val_accuracy: 0.8337\n",
            "Epoch 272/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1278 - accuracy: 0.8934 - val_loss: 0.4056 - val_accuracy: 0.8364\n",
            "Epoch 273/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.8950 - val_loss: 0.4155 - val_accuracy: 0.8340\n",
            "Epoch 274/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1225 - accuracy: 0.8955 - val_loss: 0.4170 - val_accuracy: 0.8331\n",
            "Epoch 275/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.8965 - val_loss: 0.4109 - val_accuracy: 0.8386\n",
            "Epoch 276/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1196 - accuracy: 0.8967 - val_loss: 0.4199 - val_accuracy: 0.8329\n",
            "Epoch 277/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1184 - accuracy: 0.8970 - val_loss: 0.4152 - val_accuracy: 0.8358\n",
            "Epoch 278/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1171 - accuracy: 0.8969 - val_loss: 0.4120 - val_accuracy: 0.8384\n",
            "Epoch 279/300\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1168 - accuracy: 0.8965 - val_loss: 0.4119 - val_accuracy: 0.8407\n",
            "Epoch 280/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1179 - accuracy: 0.8954 - val_loss: 0.4157 - val_accuracy: 0.8341\n",
            "Epoch 281/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1228 - accuracy: 0.8928 - val_loss: 0.4080 - val_accuracy: 0.8412\n",
            "Epoch 282/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.8957 - val_loss: 0.4060 - val_accuracy: 0.8413\n",
            "Epoch 283/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1098 - accuracy: 0.8982 - val_loss: 0.4101 - val_accuracy: 0.8393\n",
            "Epoch 284/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1041 - accuracy: 0.9006 - val_loss: 0.4037 - val_accuracy: 0.8395\n",
            "Epoch 285/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9027 - val_loss: 0.4051 - val_accuracy: 0.8417\n",
            "Epoch 286/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.1003 - accuracy: 0.9022 - val_loss: 0.4041 - val_accuracy: 0.8425\n",
            "Epoch 287/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0960 - accuracy: 0.9041 - val_loss: 0.4107 - val_accuracy: 0.8418\n",
            "Epoch 288/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0937 - accuracy: 0.9052 - val_loss: 0.4117 - val_accuracy: 0.8435\n",
            "Epoch 289/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0925 - accuracy: 0.9057 - val_loss: 0.4063 - val_accuracy: 0.8443\n",
            "Epoch 290/300\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0920 - accuracy: 0.9057 - val_loss: 0.4153 - val_accuracy: 0.8405\n",
            "Epoch 291/300\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0900 - accuracy: 0.9069 - val_loss: 0.4112 - val_accuracy: 0.8441\n",
            "Epoch 292/300\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0872 - accuracy: 0.9078 - val_loss: 0.4130 - val_accuracy: 0.8432\n",
            "Epoch 293/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0868 - accuracy: 0.9058 - val_loss: 0.4085 - val_accuracy: 0.8416\n",
            "Epoch 294/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0913 - accuracy: 0.9028 - val_loss: 0.4044 - val_accuracy: 0.8448\n",
            "Epoch 295/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0915 - accuracy: 0.9025 - val_loss: 0.4154 - val_accuracy: 0.8336\n",
            "Epoch 296/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0977 - accuracy: 0.8987 - val_loss: 0.3969 - val_accuracy: 0.8450\n",
            "Epoch 297/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0878 - accuracy: 0.9026 - val_loss: 0.3980 - val_accuracy: 0.8418\n",
            "Epoch 298/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9061 - val_loss: 0.3999 - val_accuracy: 0.8406\n",
            "Epoch 299/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9075 - val_loss: 0.3917 - val_accuracy: 0.8448\n",
            "Epoch 300/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9091 - val_loss: 0.3904 - val_accuracy: 0.8457\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d0f482c8ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s_erros.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kel7j3akyTbT",
        "outputId": "770b2ed4-ae50-4050-d25e-aded0442c990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0702 - accuracy: 0.9108 - val_loss: 0.3994 - val_accuracy: 0.8445\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0675 - accuracy: 0.9118 - val_loss: 0.3967 - val_accuracy: 0.8451\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9128 - val_loss: 0.3957 - val_accuracy: 0.8459\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0658 - accuracy: 0.9129 - val_loss: 0.3936 - val_accuracy: 0.8459\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0663 - accuracy: 0.9123 - val_loss: 0.3943 - val_accuracy: 0.8461\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9129 - val_loss: 0.3903 - val_accuracy: 0.8467\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9101 - val_loss: 0.3932 - val_accuracy: 0.8469\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0714 - accuracy: 0.9103 - val_loss: 0.4084 - val_accuracy: 0.8451\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0793 - accuracy: 0.9069 - val_loss: 0.4196 - val_accuracy: 0.8407\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0827 - accuracy: 0.9054 - val_loss: 0.3916 - val_accuracy: 0.8468\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9075 - val_loss: 0.3950 - val_accuracy: 0.8454\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0722 - accuracy: 0.9096 - val_loss: 0.3903 - val_accuracy: 0.8489\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9129 - val_loss: 0.3894 - val_accuracy: 0.8499\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0616 - accuracy: 0.9155 - val_loss: 0.3970 - val_accuracy: 0.8472\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9159 - val_loss: 0.3865 - val_accuracy: 0.8501\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0596 - accuracy: 0.9165 - val_loss: 0.3897 - val_accuracy: 0.8506\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0621 - accuracy: 0.9147 - val_loss: 0.4008 - val_accuracy: 0.8470\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0615 - accuracy: 0.9153 - val_loss: 0.3896 - val_accuracy: 0.8494\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0617 - accuracy: 0.9153 - val_loss: 0.4104 - val_accuracy: 0.8434\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9160 - val_loss: 0.3934 - val_accuracy: 0.8496\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0617 - accuracy: 0.9149 - val_loss: 0.3911 - val_accuracy: 0.8501\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0603 - accuracy: 0.9160 - val_loss: 0.4050 - val_accuracy: 0.8483\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0639 - accuracy: 0.9149 - val_loss: 0.3944 - val_accuracy: 0.8475\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9060 - val_loss: 0.4042 - val_accuracy: 0.8462\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0861 - accuracy: 0.9044 - val_loss: 0.3946 - val_accuracy: 0.8466\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0902 - accuracy: 0.9021 - val_loss: 0.3935 - val_accuracy: 0.8476\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0711 - accuracy: 0.9113 - val_loss: 0.3918 - val_accuracy: 0.8499\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0626 - accuracy: 0.9152 - val_loss: 0.3982 - val_accuracy: 0.8482\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0588 - accuracy: 0.9167 - val_loss: 0.3951 - val_accuracy: 0.8497\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0565 - accuracy: 0.9178 - val_loss: 0.4025 - val_accuracy: 0.8491\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9195 - val_loss: 0.3985 - val_accuracy: 0.8501\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0550 - accuracy: 0.9189 - val_loss: 0.3945 - val_accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0535 - accuracy: 0.9197 - val_loss: 0.3963 - val_accuracy: 0.8534\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0540 - accuracy: 0.9192 - val_loss: 0.3967 - val_accuracy: 0.8514\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9204 - val_loss: 0.3999 - val_accuracy: 0.8520\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0515 - accuracy: 0.9209 - val_loss: 0.3994 - val_accuracy: 0.8519\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0515 - accuracy: 0.9206 - val_loss: 0.4027 - val_accuracy: 0.8494\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0536 - accuracy: 0.9192 - val_loss: 0.3963 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9172 - val_loss: 0.3934 - val_accuracy: 0.8530\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0573 - accuracy: 0.9178 - val_loss: 0.4013 - val_accuracy: 0.8511\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9140 - val_loss: 0.4063 - val_accuracy: 0.8496\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9085 - val_loss: 0.4006 - val_accuracy: 0.8478\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0818 - accuracy: 0.9072 - val_loss: 0.4041 - val_accuracy: 0.8467\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0744 - accuracy: 0.9097 - val_loss: 0.3902 - val_accuracy: 0.8512\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0621 - accuracy: 0.9156 - val_loss: 0.3907 - val_accuracy: 0.8517\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0558 - accuracy: 0.9183 - val_loss: 0.3857 - val_accuracy: 0.8541\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9200 - val_loss: 0.3877 - val_accuracy: 0.8539\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0504 - accuracy: 0.9211 - val_loss: 0.3961 - val_accuracy: 0.8518\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9211 - val_loss: 0.3979 - val_accuracy: 0.8521\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9217 - val_loss: 0.3923 - val_accuracy: 0.8536\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0505 - accuracy: 0.9207 - val_loss: 0.3978 - val_accuracy: 0.8536\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0490 - accuracy: 0.9218 - val_loss: 0.3943 - val_accuracy: 0.8541\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9209 - val_loss: 0.3930 - val_accuracy: 0.8538\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0503 - accuracy: 0.9206 - val_loss: 0.3948 - val_accuracy: 0.8543\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0522 - accuracy: 0.9198 - val_loss: 0.4027 - val_accuracy: 0.8489\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0613 - accuracy: 0.9156 - val_loss: 0.3992 - val_accuracy: 0.8510\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0745 - accuracy: 0.9094 - val_loss: 0.4073 - val_accuracy: 0.8486\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.0759 - accuracy: 0.9087 - val_loss: 0.3943 - val_accuracy: 0.8519\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0631 - accuracy: 0.9146 - val_loss: 0.3920 - val_accuracy: 0.8529\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0564 - accuracy: 0.9177 - val_loss: 0.3940 - val_accuracy: 0.8541\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0519 - accuracy: 0.9200 - val_loss: 0.3913 - val_accuracy: 0.8551\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9213 - val_loss: 0.3918 - val_accuracy: 0.8548\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0473 - accuracy: 0.9223 - val_loss: 0.3888 - val_accuracy: 0.8553\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0465 - accuracy: 0.9230 - val_loss: 0.3920 - val_accuracy: 0.8542\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9227 - val_loss: 0.3914 - val_accuracy: 0.8548\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9225 - val_loss: 0.3939 - val_accuracy: 0.8538\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9224 - val_loss: 0.3950 - val_accuracy: 0.8537\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0488 - accuracy: 0.9215 - val_loss: 0.3955 - val_accuracy: 0.8543\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0470 - accuracy: 0.9224 - val_loss: 0.3947 - val_accuracy: 0.8542\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0521 - accuracy: 0.9201 - val_loss: 0.3970 - val_accuracy: 0.8516\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0572 - accuracy: 0.9178 - val_loss: 0.4045 - val_accuracy: 0.8487\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9121 - val_loss: 0.4072 - val_accuracy: 0.8484\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0733 - accuracy: 0.9108 - val_loss: 0.4004 - val_accuracy: 0.8522\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9108 - val_loss: 0.3896 - val_accuracy: 0.8534\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0625 - accuracy: 0.9153 - val_loss: 0.3864 - val_accuracy: 0.8541\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9175 - val_loss: 0.3812 - val_accuracy: 0.8562\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9182 - val_loss: 0.3791 - val_accuracy: 0.8554\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0455 - accuracy: 0.9218 - val_loss: 0.3819 - val_accuracy: 0.8566\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9228 - val_loss: 0.3812 - val_accuracy: 0.8571\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9233 - val_loss: 0.3835 - val_accuracy: 0.8557\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0425 - accuracy: 0.9229 - val_loss: 0.3909 - val_accuracy: 0.8546\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0430 - accuracy: 0.9226 - val_loss: 0.3846 - val_accuracy: 0.8563\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0422 - accuracy: 0.9231 - val_loss: 0.3856 - val_accuracy: 0.8556\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9229 - val_loss: 0.3846 - val_accuracy: 0.8563\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9230 - val_loss: 0.3885 - val_accuracy: 0.8557\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9234 - val_loss: 0.3878 - val_accuracy: 0.8562\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9223 - val_loss: 0.3841 - val_accuracy: 0.8568\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0416 - accuracy: 0.9229 - val_loss: 0.3854 - val_accuracy: 0.8551\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9226 - val_loss: 0.3824 - val_accuracy: 0.8551\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0465 - accuracy: 0.9207 - val_loss: 0.3872 - val_accuracy: 0.8555\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9112 - val_loss: 0.4514 - val_accuracy: 0.8323\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0869 - accuracy: 0.9039 - val_loss: 0.3962 - val_accuracy: 0.8502\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0654 - accuracy: 0.9124 - val_loss: 0.3779 - val_accuracy: 0.8561\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0494 - accuracy: 0.9193 - val_loss: 0.3864 - val_accuracy: 0.8566\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9205 - val_loss: 0.3792 - val_accuracy: 0.8568\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9225 - val_loss: 0.3787 - val_accuracy: 0.8570\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9236 - val_loss: 0.3764 - val_accuracy: 0.8578\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0384 - accuracy: 0.9241 - val_loss: 0.3792 - val_accuracy: 0.8569\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9245 - val_loss: 0.3794 - val_accuracy: 0.8580\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0374 - accuracy: 0.9247 - val_loss: 0.3863 - val_accuracy: 0.8551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "\n",
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Ground truth:', target_texts[seq_index])\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    print('On how many positions they agree on', matching_position_k_mers(target_texts[seq_index], decoded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfo_Bo9Sya54",
        "outputId": "dc0a6e06-a3b4-436e-b26f-56ff1bda0543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 342ms/step\n",
            "-\n",
            "Ground truth: \tNTTTTGCAGCCG\n",
            "\n",
            "Input sentence: NTTTTGCAGCCG\n",
            "Decoded sentence: NTTTTGCAGCCG\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "-\n",
            "Ground truth: \tTTTTGCAGCCGA\n",
            "\n",
            "Input sentence: TTNTGCAGCCGA\n",
            "Decoded sentence: TTTTGCAGCCGC\n",
            "\n",
            "On how many positions they agree on {12}\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "-\n",
            "Ground truth: \tTTTGCAGCCGAT\n",
            "\n",
            "Input sentence: TTTGCAGCCGAN\n",
            "Decoded sentence: TTTGCAGCCGAT\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tTTGCAGCCGATC\n",
            "\n",
            "Input sentence: TTNCAGCCGATC\n",
            "Decoded sentence: TTGCAGCCGATC\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Ground truth: \tTGCAGCCGATCA\n",
            "\n",
            "Input sentence: TGCANCCGATCA\n",
            "Decoded sentence: TGCAGCCGATCC\n",
            "\n",
            "On how many positions they agree on {12}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Ground truth: \tGCAGCCGATCAT\n",
            "\n",
            "Input sentence: GCANCCGATCAT\n",
            "Decoded sentence: GCAGCCGATCAT\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tCAGCCGATCATC\n",
            "\n",
            "Input sentence: NAGCCGATCATC\n",
            "Decoded sentence: CAGCCGATCATC\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Ground truth: \tAGCCGATCATCA\n",
            "\n",
            "Input sentence: AGCCGATCANCA\n",
            "Decoded sentence: AGCCGATCATCC\n",
            "\n",
            "On how many positions they agree on {12}\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Ground truth: \tGCCGATCATCAG\n",
            "\n",
            "Input sentence: GNCGATCATCAG\n",
            "Decoded sentence: GCCGATCATCAG\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tCCGATCATCAGC\n",
            "\n",
            "Input sentence: CCNATCATCAGC\n",
            "Decoded sentence: CCGATCATCAGC\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Ground truth: \tCGATCATCAGCA\n",
            "\n",
            "Input sentence: CGANCATCAGCA\n",
            "Decoded sentence: CGATCATCAGCA\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tGATCATCAGCAC\n",
            "\n",
            "Input sentence: GATCATCANCAC\n",
            "Decoded sentence: GATCATCAGCAC\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tATCATCAGCACA\n",
            "\n",
            "Input sentence: ATNATCAGCACA\n",
            "Decoded sentence: ATCATCAGCACA\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Ground truth: \tTCATCAGCACAT\n",
            "\n",
            "Input sentence: TCATCAGCACNT\n",
            "Decoded sentence: TCATCAGCACAT\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Ground truth: \tCATCAGCACATC\n",
            "\n",
            "Input sentence: CATCAGCACANC\n",
            "Decoded sentence: CATCAGCACATC\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "-\n",
            "Ground truth: \tATCAGCACATCT\n",
            "\n",
            "Input sentence: ATCNGCACATCT\n",
            "Decoded sentence: ATCAGCACATCT\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Ground truth: \tTCAGCACATCTA\n",
            "\n",
            "Input sentence: TCANCACATCTA\n",
            "Decoded sentence: TCAGCACATCTA\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Ground truth: \tCAGCACATCTAG\n",
            "\n",
            "Input sentence: CAGCACANCTAG\n",
            "Decoded sentence: CAGCACATCTAG\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Ground truth: \tAGCACATCTAGG\n",
            "\n",
            "Input sentence: AGNACATCTAGG\n",
            "Decoded sentence: AGCACATCTAGG\n",
            "\n",
            "On how many positions they agree on {13}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Ground truth: \tGCACATCTAGGT\n",
            "\n",
            "Input sentence: GCACANCTAGGT\n",
            "Decoded sentence: GCACATCTAGGT\n",
            "\n",
            "On how many positions they agree on {13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_lines_with_character(input_file, output_file, character='N'):\n",
        "    with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
        "        for line in f_in:\n",
        "            # Podziel linię na kolumny (oddzielone spacją)\n",
        "            column1, column2 = line.strip().split(' ')\n",
        "            # Sprawdź, czy w którejś kolumnie występuje znak 'N'\n",
        "            if character in column1 or character in column2:\n",
        "                # Jeśli tak, zapisz linię w pliku wynikowym\n",
        "                f_out.write(line)\n",
        "\n",
        "# Przykład użycia funkcji\n",
        "input_file = 'long_dna.txt'\n",
        "output_file = 'errors.txt'\n",
        "filter_lines_with_character(input_file, output_file, character='N')\n"
      ],
      "metadata": {
        "id": "ToH6-vOKz9U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10000\n",
        "data_path = 'errors.txt'\n",
        "input_texts, target_texts, input_characters, target_characters = parse_data_file(data_path, num_samples)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Liczba danych wejściowych:\", len(input_texts))\n",
        "print(\"Liczba danych wyjściowych:\", len(target_texts))\n",
        "print(\"Zbiór znaków wejściowych:\", input_characters)\n",
        "print(\"Zbiór znaków wyjściowych:\", target_characters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojb-yndOL_FL",
        "outputId": "9c1ab001-36ac-4bb9-eb96-eef78bd752ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba danych wejściowych: 53\n",
            "Liczba danych wyjściowych: 53\n",
            "Zbiór znaków wejściowych: {'N', 'T', 'A', 'G', 'C'}\n",
            "Zbiór znaków wyjściowych: {'\\t', 'N', 'T', '\\n', 'A', 'G', 'C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "input_token_index = create_token_index(input_characters)\n",
        "target_token_index = create_token_index(target_characters)\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = transform_data(input_texts, target_texts, input_token_index, target_token_index, max_encoder_seq_length, max_decoder_seq_length)\n",
        "\n",
        "# Wyświetlenie informacji o danych\n",
        "print(\"Number of unique input tokens:\", len(input_token_index))\n",
        "print(\"Number of unique output tokens:\", len(target_token_index))\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCnCDmh_MChw",
        "outputId": "9a3ea692-b1fc-4590-e3dd-a8739e8687f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique input tokens: 5\n",
            "Number of unique output tokens: 7\n",
            "Max sequence length for inputs: 12\n",
            "Max sequence length for outputs: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(50):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    print('On how many positions they agree on', matching_position_k_mers(input_texts[seq_index], decoded_sentence, space = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_GrUr2KMNW2",
        "outputId": "65dd6198-6cc0-41ff-9b61-b1e86c67c1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: ACGGAACGTTCT\n",
            "Decoded sentence: CCGGACGCAACA\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: CGGAACGTTCTN\n",
            "Decoded sentence: CGGTGCGAACAT\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GGAACGTTCTNA\n",
            "Decoded sentence: GGCTCGAACATG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: GAACGTTCTNAA\n",
            "Decoded sentence: GCTCGAACATCTA\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: AACGTTCTNAAA\n",
            "Decoded sentence: GACGAACATGTG\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: ACGTTCTNAAAA\n",
            "Decoded sentence: TCGAACATTGAT\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: CGTTCTNAAAAG\n",
            "Decoded sentence: CGAACATACGTG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "-\n",
            "Input sentence: GTTCTNAAAAGA\n",
            "Decoded sentence: GAACATTAAGGT\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "-\n",
            "Input sentence: TTCTNAAAAGAG\n",
            "Decoded sentence: AACATATATGTG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TCTNAAAAGAGC\n",
            "Decoded sentence: ACATATTGGTGC\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: CTNAAAAGAGCT\n",
            "Decoded sentence: CATGTAGTGACA\n",
            "\n",
            "On how many positions they agree on {3}\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-\n",
            "Input sentence: TNAAAAGAGCTA\n",
            "Decoded sentence: ATCGCAGTGCAC\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: NAAAAGAGCTAT\n",
            "Decoded sentence: TTCTGGTGCACC\n",
            "\n",
            "On how many positions they agree on {3}\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-\n",
            "Input sentence: AACCTGTGCTTG\n",
            "Decoded sentence: AGCCAGAGCAAG\n",
            "\n",
            "On how many positions they agree on {7}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: ACCTGTGCTTGN\n",
            "Decoded sentence: ACCAGAGCAAGT\n",
            "\n",
            "On how many positions they agree on {7}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: CCTGTGCTTGNG\n",
            "Decoded sentence: CCAGAGCAAGTG\n",
            "\n",
            "On how many positions they agree on {7}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: CTGTGCTTGNGA\n",
            "Decoded sentence: CAGAGCAAGTGT\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: TGTGCTTGNGAA\n",
            "Decoded sentence: AGAGCAAGTGTG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: GTGCTTGNGAAA\n",
            "Decoded sentence: GAGCAAGTGTCT\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: TGCTTGNGAAAT\n",
            "Decoded sentence: AGCAAGTGTAAA\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GCTTGNGAAATT\n",
            "Decoded sentence: GCAAGTGGTAAC\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "-\n",
            "Input sentence: CTTGNGAAATTG\n",
            "Decoded sentence: CAAGTGTGAAAG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: TTGNGAAATTGT\n",
            "Decoded sentence: AAGTGGTCAAGA\n",
            "\n",
            "On how many positions they agree on {3}\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: TGNGAAATTGTC\n",
            "Decoded sentence: AGTGGTAAGAAC\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: GNGAAATTGTCG\n",
            "Decoded sentence: GTGATAAAGAGA\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: NGAAATTGTCGG\n",
            "Decoded sentence: TGTGCAAGACGG\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: ATGGTCTTTGTT\n",
            "Decoded sentence: AAGGACAAAGAA\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: TGGTCTTTGTTN\n",
            "Decoded sentence: AGGACAAAGAAT\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: GGTCTTTGTTNN\n",
            "Decoded sentence: GGACAAAGAATT\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GTCTTTGTTNNT\n",
            "Decoded sentence: GACAAAGAATTA\n",
            "\n",
            "On how many positions they agree on {3}\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: TCTTTGTTNNTT\n",
            "Decoded sentence: ACAAAGAATTAA\n",
            "\n",
            "On how many positions they agree on {2}\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: CTTTGTTNNTTT\n",
            "Decoded sentence: CAAAGAATTAAA\n",
            "\n",
            "On how many positions they agree on {2}\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "Input sentence: TTTGTTNNTTTT\n",
            "Decoded sentence: AAAGAATTAAAA\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "Input sentence: TTGTTNNTTTTT\n",
            "Decoded sentence: AAGAATTAAACA\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: TGTTNNTTTTTT\n",
            "Decoded sentence: AGAATTAAAAAA\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: GTTNNTTTTTTT\n",
            "Decoded sentence: GAATTAAAAAAA\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: TTNNTTTTTTTG\n",
            "Decoded sentence: AATTAAAAAAAG\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: TNNTTTTTTTGT\n",
            "Decoded sentence: ATTAAAAAAAGA\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: NNTTTTTTTGTA\n",
            "Decoded sentence: TTAAAAAAAGAC\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: NTTTTTTTGTAT\n",
            "Decoded sentence: TAAAAAAAGACC\n",
            "\n",
            "On how many positions they agree on {1}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: ATGAGGCTGGTT\n",
            "Decoded sentence: GAGTGGCAGGAA\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: TGAGGCTGGTTN\n",
            "Decoded sentence: AGGGGCAGGAAT\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GAGGCTGGTTNT\n",
            "Decoded sentence: GTGGCAGGAATA\n",
            "\n",
            "On how many positions they agree on {6}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: AGGCTGGTTNTA\n",
            "Decoded sentence: TGGCAGGAAGAT\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GGCTGGTTNTAA\n",
            "Decoded sentence: GGCAGGAATGAA\n",
            "\n",
            "On how many positions they agree on {7}\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: GCTGGTTNTAAA\n",
            "Decoded sentence: GCAGGAATAACC\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "-\n",
            "Input sentence: CTGGTTNTAAAT\n",
            "Decoded sentence: CAGGAATAGCCC\n",
            "\n",
            "On how many positions they agree on {3}\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-\n",
            "Input sentence: TGGTTNTAAATC\n",
            "Decoded sentence: AGGAATACGAAC\n",
            "\n",
            "On how many positions they agree on {4}\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: GGTTNTAAATCA\n",
            "Decoded sentence: GGAATAAGAACT\n",
            "\n",
            "On how many positions they agree on {5}\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "Input sentence: GTTNTAAATCAC\n",
            "Decoded sentence: GAATAGTCAAAA\n",
            "\n",
            "On how many positions they agree on {2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0eEw7Y5Xcux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}